Transformer networks are deep neural networks now widely used for neural natural language processing, including handling search queries, question answering, image captioning, and translating between languages.

### Introductory Tutorials on Transformers
* [video](https://www.youtube.com/watch?v=SZorAJ4I-sA) (9:10) and [text](https://daleonai.com/transformers-explained): Transformers Explained: Understand the Model Behind GPT, BERT, and T5
* [Transformer: A Novel Neural Network Architecture for Language Understanding](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html), Google AI blog. Very accessible introduction.
* [Language Processing with BERT: The 3 Minute Intro (Deep learning for NLP)](https://www.youtube.com/watch?v=ioGry-89gqE)
* [How Transformers Work in Deep Learning and NLP](https://theaisummer.com/transformer/)
* [Getting Meaning From Text](https://peltarion.com/blog/data-science/self-attention-video)
* [A deep dive into BERT: How BERT launched a rocket into natural language understanding](https://searchengineland.com/a-deep-dive-into-bert-how-bert-launched-a-rocket-into-natural-language-understanding-324522)

### More Technical Tutorials
* [Transformers From Scratch (Rohrer)](https://e2eml.school/transformers.html)
* [Transformers From Scratch (Bloem)](http://peterbloem.nl/blog/transformers)
* [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
* [Transformer model for language understanding](https://www.tensorflow.org/text/tutorials/transformer) (TensorFlow tutorial on language translation)
* [Language modeling with nn.Transformer and TorchText](https://pytorch.org/tutorials/beginner/transformer_tutorial.html) (PyTorch tutorial)

### Technical Videos on Transformers
* [The Narrated Transformer Language Model](https://www.youtube.com/watch?v=-QH8fRhqFHM)
* [Tensor2Tensor Transformers](https://www.youtube.com/watch?v=rBCqOTEfxvg)
* [GPT-3: Language Models are Few-Shot Learners (Paper Explained)](https://www.youtube.com/watch?v=SY5PvZrJhLE) (1:04:29)
* A Visual Guide to Transformer Neural Networks (series):
* * [Episode 1: Position Embeddings](https://www.youtube.com/watch?v=dichIcUZfOw&list=PL86uXYUJ7999zE8u2-97i4KG_2Zpufkfb&index=2)
* * [Episode 2: Multi-Head & Self-Attention](https://www.youtube.com/watch?v=mMa2PmYJlCo&list=PL86uXYUJ7999zE8u2-97i4KG_2Zpufkfb)
* * [Episode 2: Decoder's Masked Attention](https://www.youtube.com/watch?v=gJ9kaJsE78k)
* [Rasa Algorithm Whiteboard - Transformers & Attention 1: Self Attention](https://www.youtube.com/watch?v=yGTUuEx3GkA)

### Question Answering Demos Using Transformers
* [Google BERT demo](https://storage.googleapis.com/tfjs-models/demos/mobilebert-qna/index.html) [direct link]
* [ML4K BERT Q&A model](https://machinelearningforkids.co.uk/#!/pretrained) [direct link]

### Text Generation Demos Using Transformers
* [Talk to Transformer](https://app.inferkit.com/demo) [direct link]
* [TextSynth](https://bellard.org/textsynth/) [direct link]

### Important Papers
* [Attention Is All You Need](https://arxiv.org/abs/1706.03762), Vaswani et al. 2017.
* [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805), Devlin et al. 2019.
* [Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation](https://arxiv.org/abs/1609.08144) Wu et al. 2016.

### Capabilites of Large Language Models
* [Google's AI Is Something Even Stranger Than Conscious](https://www.theatlantic.com/technology/archive/2022/06/google-palm-ai-artificial-consciousness/661329/), Stephen Marche, The Atlantic, June 19, 2022

### Other Resources
* [Simple Transformer Language Model](https://colab.research.google.com/github/jalammar/jalammar.github.io/blob/master/notebooks/Simple_Transformer_Language_Model.ipynb#scrollTo=BstYQU6NkkDA) (Python notebook in CoLab)
* [SQuAD: Stanford Question Answering Dataset](https://rajpurkar.github.io/SQuAD-explorer/) used to train some BERT models